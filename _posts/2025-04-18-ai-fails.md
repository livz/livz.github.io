---
title: "When AI Gets It Wrong"
categories: [Experiment]
---

![AI fail robot](/assets/images/ai-fail/robot.png)

<blockquote>
  <p>The great thing about AI is that it always has an answer</p>
</blockquote>

Artificial Intelligence has made enormous stridesâ€”from writing essays to generating code and even helping with medical diagnoses. But for all its shiny capabilities, AI can still fumble in ways that are as entertaining as they are exasperating. Behind the polished interface lies (no pun intended) a model that occasionally insists 7 Ã— 8 = 54, cites scientific studies that donâ€™t exist, or gets tangled up in its own logic.

In this quick post, weâ€™ll take a tour of some interesting AI blunders:

- **Calculation errors**  
- **Logical mistakes**  
- **Hallucinations**
- **Bonus: Inventions**

---

## 1. When the Numbers Donâ€™t Add Up - Calculation Errors

On the surface, maths seems like the last thing an AI would mess up. After all, itâ€™s a machine. But hereâ€™s the catch: many language models donâ€™t actually *do* mathâ€”they imitate how math *sounds*. This distinction becomes painfully clear when an AI gives you a 20% tip on a Â£43 bill and confidently reports it as Â£17.

**ðŸ” Why it happens** 

Language models arenâ€™t calculators. Theyâ€™ve learned what *looks like* a correct answer in context, not how to compute one.

**ðŸ“Ž Classic examples**
- Miscalculating percentages or totals.
- Confusing units (e.g., converting miles to kilometres with wild abandon).
- Botching sequences: â€œWhatâ€™s the next number in 2, 4, 8?â€ â†’ â€œ15!â€

**ðŸ«€Human Notes**

AI got really better at calculations nowadays, but this type of errors still happens:
![AI fail robot](/assets/images/ai-fail/calculation-question.png)
Here I was asking ChatGPT to ask as a teacher and create a battery of questions for a 6-year old child. Let's see how it evaluated the answer:
![AI fail robot](/assets/images/ai-fail/calculation-answer.png)

**ðŸ§  Takeaway**

Always double-check AIâ€™s maths, your teacher might not find your vibe-solving that funny.

---

## 2. The AI That Tripped Over Its Own Brain - Logical Mistakes

Ask an AI to solve a riddle or follow a basic logical sequence, and you might witness a meltdown in slow motion. AIs can construct beautifully worded responses that are *logically incoherent*.

**ðŸ” Why it happens** 

AI doesn't have a mental model of time, space, or causality. It's generating the next best-sounding word, not applying reasoning.

**ðŸ“Ž Classic examples**

- "If the day after tomorrow is Friday, what day is today?" â†’ "Wednesday"
- "John has twice as many apples as Sarah, who has 3. How many does John have?" â†’ "8, because apples are delicious."

**ðŸ«€Human Notes**

For known riddles and logical problems, AI is really good nowadays:
![AI fail robot](/assets/images/ai-fail/logic-correct.png)

For new ones, however, it's confidetaly and interestingly wrong:
![AI fail robot](/assets/images/ai-fail/logic-correct.png)

**ðŸ§  Takeaway**  

While AI can write a convincing murder mystery, it may struggle to keep track of *who* committed the crime by the final chapter.

---

## 3. The Confident Liar - Hallucinations

There are no mushrooms involved here â€” just confident nonsense. This is perhaps the most dangerous category: hallucinations. These are not harmless slipsâ€”ups, made-up facts wrapped in confidence and delivered with a straight face.

**ðŸ” Why it happens**  

AI models donâ€™t know when they donâ€™t know. So instead of saying, "Iâ€™m not sure" they improvise.

**ðŸ“Ž Classic examples**

- Recommending `pip install hyperspeedmath`â€”a package that doesnâ€™t exist.
- Citing research papers with impressive-sounding titles, authors, and DOIs... that lead nowhere.
- Giving Python functions fake parameters: `turbo=True` in `pandas.read_csv()`.

**ðŸ§  Takeaway**  

Ask AI to provide sources and referenes, cross-check them, especially when dealing with citations, legal texts, or anything you canâ€™t afford to get wrong. If it sounds too smart to be realâ€”it might be.

**ðŸ«€Human Notes**

Out of the _many many_ examples I've encountered, here's the most recent one where ChatGPT invented a package name that was never on brew and provided installation instructions:
![AI fail robot](/assets/images/ai-fail/hallucinations-answer.png)
When prompted for clarification, it apparently recognised its mistake:
![AI fail robot](/assets/images/ai-fail/hallucinations-recheck.png)

---
## 4. The Phantom Biographer â€“ When AI Writes Your Fictional Life

Ask an AI who you are, and it might hold up a mirrorâ€¦ that bends reality. While it can summarise your messages quite well, ask it to â€œtell me about myselfâ€ and suddenly it remembers conversations you never had, jobs you never mentioned, and hobbies youâ€™ve never tried.

**ðŸ” Why it happens**  

Language models generate responses based on patterns and probabilities â€” not true memory. When asked about you, theyâ€™ll try to stitch together an answer from whatever feels "on theme," even if it's fiction. If the dataset smells like you love jazz and cats, guess what? Youâ€™re a saxophonist with three tabbies.

**ðŸ“Ž Classic examples**

- "Based on our conversations, you're a yoga teacher who lives in Canada" But youâ€™re an accountant in Liverpool.
- "Youâ€™ve mentioned you enjoy ice climbing" Never once. Terrified of heights.
- "As a long-time Android developer" You've only talked about Python.

**ðŸ§  Takeaway**  

Treat AI's reflections with caution. If it says something about you that sounds off, it probably is. These arenâ€™t intentional liesâ€”theyâ€™re improvisations dressed as insight.

**ðŸ«€Human Notes**

This blog post? Sparked by one such moment. I asked ChatGPT to summarise what it knew about me. It nailed most of it:

But then  I asekd .... Suddenly I had hobbies, habits, and a hometown Iâ€™d never heard of. It was like a conversation with someone who thinks they know you but really just read your tweets once.

---
## Conclusion

AI is impressive, but itâ€™s not omniscient. Like a well-meaning intern, it can be fast, enthusiastic, and occasionally very wrong. Understanding the types of mistakes it makes helps us use it more wisely and avoid being led down the garden path by a bot with a PhD in bluffing.

**Golden Rule:** *Trust but verify*. AI can speed you up, spark ideas, and take care of repetitive work, but the final judgment call is still yours.

**Note:** Ironically, except the examples, this blog post was mostly generated with ChatGPT ðŸ™ƒðŸ˜ˆ

---

> Don't forget who you're talking to.

*Got your own favourite AI fail? Drop me a message minime@craftware.xyz*
