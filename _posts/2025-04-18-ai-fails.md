---
title: "When AI Gets It Wrong"
categories: [Experiment]
---

![AI fail robot](/assets/images/ai-fail/robot.png)

<blockquote>
  <p>The great thing about AI is that it always has an answer</p>
</blockquote>

# When AI Gets It Wrong: Funny, Frustrating, and Fascinating Fails

Artificial Intelligence has made enormous stridesâ€”from writing essays to generating code and even helping with medical diagnoses. But for all its shiny capabilities, AI can still fumble in ways that are as entertaining as they are exasperating. Behind the polished interface lies (no pun intended) a model that occasionally insists 7 Ã— 8 = 54, cites scientific studies that donâ€™t exist, or gets tangled up in its own logic.

In this quick post, weâ€™ll take a tour of some interesting AI blunders:

- **Calculation errors**  
- **Logical mistakes**  
- **Hallucinations**
- **Bonus: Inventions**

---

## 1. Calculation Errors â€“ When the Numbers Donâ€™t Add Up

On the surface, maths seems like the last thing an AI would mess up. After all, itâ€™s a machine. But hereâ€™s the catch: many language models donâ€™t actually *do* mathâ€”they imitate how math *sounds*. This distinction becomes painfully clear when an AI gives you a 20% tip on a Â£43 bill and confidently reports it as Â£17.

**ðŸ” Why it happens** 
Language models arenâ€™t calculators. Theyâ€™ve learned what *looks like* a correct answer in context, not how to compute one.

**ðŸ“Ž Classic examples**
- Miscalculating percentages or totals.
- Confusing units (e.g., converting miles to kilometres with wild abandon).
- Botching sequences: â€œWhatâ€™s the next number in 2, 4, 8?â€ â†’ â€œ15!â€

**ðŸ«€Human Notes**
AI got really better at calculations nowadays, but this type of errors still happens:
![AI fail robot](/assets/images/ai-fail/calculation-question.png)
Here I was asking ChatGPT to ask as a teacher and create a battery of questions for a 6-year old child. Let's see how it evaluated the answer:
![AI fail robot](/assets/images/ai-fail/calculation-answer.png)

**ðŸ§  Takeaway**
Always double-check AIâ€™s maths, your teacher might not find your vibe-solving that funny.

---

## 2. Logical Mistakes â€“ The AI That Tripped Over Its Own Brain

Ask an AI to solve a riddle or follow a basic logical sequence, and you might witness a meltdown in slow motion. AIs can construct beautifully worded responses that are *logically incoherent*.

**ðŸ” Why it happens**  
AI doesn't have a mental model of time, space, or causality. It's generating the next best-sounding word, not applying reasoning.

**ðŸ“Ž Classic examples:**
- â€œIf the day after tomorrow is Friday, what day is today?â€ â†’ â€œWednesdayâ€  
- â€œJohn has twice as many apples as Sarah, who has 3. How many does John have?â€ â†’ â€œ8, because apples are delicious.â€

**ðŸ«€Human Notes**
For known riddles and logical problems, AI is really good nowadays:
![AI fail robot](/assets/images/ai-fail/logic-correct.png.png)

For new ones, however, it's confidetaly and interestingly wrong:
![AI fail robot](/assets/images/ai-fail/logic-correct.png.png)

**ðŸ§  Takeaway**  
While AI can write a convincing murder mystery, it may struggle to keep track of *who* committed the crime by the final chapter.

---

## 3. Hallucinations â€“ The Confident Liar

_(No mushrooms involved â€” just confident nonsense)_
This is perhaps the most dangerous category: hallucinations. These are not harmless slipsâ€”ups, made-up facts wrapped in confidence and delivered with a straight face.

**ðŸ” Why it happens**  
AI models donâ€™t know when they donâ€™t know. So instead of saying, â€œIâ€™m not sure,â€ they improvise.

**ðŸ“Ž Classic examples**
- Recommending `pip install hyperspeedmath`â€”a package that doesnâ€™t exist.
- Citing research papers with impressive-sounding titles, authors, and DOIs... that lead nowhere.
- Giving Python functions fake parameters: `turbo=True` in `pandas.read_csv()`.

**ðŸ§  Takeaway**  
Ask AI to provide sources and referenes, cross-check them, especially when dealing with citations, legal texts, or anything you canâ€™t afford to get wrong. If it sounds too smart to be realâ€”it might be.

**ðŸ«€Human Notes**
Out of the _many many examples_ I've encountered, here's the most recent one where ChatGPT invented a package name that was never on brew and provided installation instructions:
![AI fail robot](/assets/images/ai-fail/hallucinations-answer.png)
When prompted for clarification, it apparently recognised its mistake:
![AI fail robot](/assets/images/ai-fail/hallucinations-recheck.png)
---

## Conclusion

AI is impressive, but itâ€™s not omniscient. Like a well-meaning intern, it can be fast, enthusiastic, and occasionally very wrong. Understanding the types of mistakes it makes helps us use it more wisely and avoid being led down the garden path by a bot with a PhD in bluffing.

**Golden Rule:** *Trust but verify*. AI can speed you up, spark ideas, and take care of repetitive work, but the final judgment call is still yours.

**Note:** Ironically, except the examples, this blog post was mostly generated with ChatGPT ðŸ™ƒðŸ˜ˆ
---

> Don't forget who you're talking to.

*Got your own favourite AI fail? Drop me a message minime@craftware.xyz*
